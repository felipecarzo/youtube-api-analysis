{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf19b2a-1bd0-4ad8-ac8c-70eb49dac784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparando o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acb25e-444d-433e-83c4-7db4e05770e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para conectar com a API do YouTube e manipulação de dados\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "from dateutil import parser\n",
    "\n",
    "# Bibliotecas para visualização de dados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Segurança para chave da API do YouTube\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Baixa as stopwords da biblioteca nltk, caso ainda não tenha feito isso\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define o conjunto de stopwords em português\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Carrega variáveis de ambiente, incluindo a chave da API\n",
    "load_dotenv() \n",
    "api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "# Definições para API do YouTube\n",
    "channel_ids = ['UC9cz05xObaFpB8U72t73IFA']\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# Inicializa o cliente da API do YouTube\n",
    "youtube = build(api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b0e11-60ca-4752-b357-3032766750df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Link com Youtube API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c259c-1e61-477e-bf2f-0984373260ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter estatísticas de um canal\n",
    "def get_channel_stats(youtube, channel_ids):\n",
    "    all_data = []\n",
    "    \n",
    "    # Solicitação à API para informações sobre o canal\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    # Extrai as informações necessárias de cada canal\n",
    "    for item in response['items']:\n",
    "        data = {\n",
    "            'channelName': item['snippet']['title'],\n",
    "            'subscribers': item['statistics']['subscriberCount'],\n",
    "            'views': item['statistics']['viewCount'],\n",
    "            'totalVideos': item['statistics']['videoCount'],\n",
    "            'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "        }\n",
    "        all_data.append(data)\n",
    "        \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Coleta estatísticas do canal\n",
    "channel_stats = get_channel_stats(youtube, channel_ids)\n",
    "channel_stats\n",
    "\n",
    "# ID da playlist de uploads do canal\n",
    "playlist_id = 'UU9cz05xObaFpB8U72t73IFA'\n",
    "\n",
    "# Função para obter IDs de vídeos de uma playlist\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    # Solicitação inicial para a playlist\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    # Armazena IDs de vídeos e lida com múltiplas páginas\n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "    \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "    \n",
    "    return video_ids\n",
    "\n",
    "# Coleta IDs dos vídeos\n",
    "video_ids = get_video_ids(youtube, playlist_id)\n",
    "len(video_ids)\n",
    "\n",
    "# Função para obter detalhes de vídeos individuais\n",
    "def get_video_details(youtube, video_ids):\n",
    "    all_video_info = []\n",
    "    \n",
    "    # Processa em lotes de até 50 vídeos devido ao limite da API\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Extrai informações relevantes para cada vídeo\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {\n",
    "                'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                'contentDetails': ['duration', 'definition', 'caption']\n",
    "            }\n",
    "            \n",
    "            video_info = {'video_id': video['id']}\n",
    "            for k, v_list in stats_to_keep.items():\n",
    "                for v in v_list:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except KeyError:\n",
    "                        video_info[v] = None\n",
    "            \n",
    "            all_video_info.append(video_info)\n",
    "                         \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "# Coleta detalhes dos vídeos\n",
    "video_df = get_video_details(youtube, video_ids)\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "video_df.isnull().any()\n",
    "video_df.dtypes\n",
    "\n",
    "# Converte colunas numéricas para tipo numérico\n",
    "numeric_cols = ['viewCount', 'likeCount', 'favouriteCount', 'commentCount']\n",
    "video_df[numeric_cols] = video_df[numeric_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "# Adiciona dia da semana em que o vídeo foi publicado\n",
    "video_df['publishedAt'] = video_df['publishedAt'].apply(lambda x: parser.parse(x))\n",
    "video_df['publishDayName'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%A\"))\n",
    "\n",
    "# Converte a duração do vídeo para segundos\n",
    "import isodate\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')\n",
    "\n",
    "# Conta o número de tags por vídeo\n",
    "video_df['tagCount'] = video_df['tags'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21127568-027b-4263-9200-d8a972f180d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Criando os gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559383fb-0a51-4dee-9c34-4c0ca4ced556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise e visualização dos dados\n",
    "\n",
    "# Gráfico de barras para visualizações dos top 9 vídeos\n",
    "ax = sns.barplot(x='title', y='viewCount', data=video_df.sort_values('viewCount', ascending=False)[0:9])\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}K'.format(x / 1000)))\n",
    "\n",
    "# Distribuição das visualizações por canal\n",
    "sns.violinplot(x='channelTitle', y='viewCount', data=video_df)\n",
    "\n",
    "# Gráficos de dispersão para análise de correlação\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "sns.scatterplot(data=video_df, x='commentCount', y='viewCount', ax=ax[0])\n",
    "sns.scatterplot(data=video_df, x='likeCount', y='viewCount', ax=ax[1])\n",
    "\n",
    "# Limpeza do título dos vídeos para geração de nuvem de palavras\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "video_df['title_no_stopwords'] = video_df['title'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "all_words_str = ' '.join([a for b in video_df['title_no_stopwords'].tolist() for a in b])\n",
    "\n",
    "# Função para plotar a nuvem de palavras\n",
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Gera a nuvem de palavras com os títulos dos vídeos\n",
    "wordcloud = WordCloud(width=2000, height=1000, random_state=1, background_color='black',\n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)\n",
    "\n",
    "# Conta o número de publicações por dia da semana\n",
    "day_df = pd.DataFrame(video_df['publishDayName'].value_counts()).rename(columns={'publishDayName': 'count'})\n",
    "day_df.index.name = 'day'\n",
    "\n",
    "# Reordena para seguir a sequência dos dias da semana\n",
    "weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_df = day_df.reindex(weekdays)\n",
    "\n",
    "# Gráfico de barras para contagem de publicações por dia da semana\n",
    "ax = day_df.reset_index().plot.bar(x='day', y='count', rot=0)\n",
    "\n",
    "# Gera relatório em PDF com visualizações\n",
    "def generate_pdf_report(video_df):\n",
    "    with PdfPages(\"youtube_report_final_design.pdf\") as pdf:\n",
    "        plt.rcParams.update({\n",
    "            'figure.facecolor': 'white',\n",
    "            'axes.facecolor': 'white',\n",
    "            'savefig.facecolor': 'white',\n",
    "            'axes.edgecolor': 'gray',\n",
    "            'grid.color': 'lightgray',\n",
    "            'axes.grid': True,\n",
    "            'axes.titleweight': 'bold',\n",
    "            'axes.titlesize': 14,\n",
    "            'axes.labelsize': 12,\n",
    "        })\n",
    "\n",
    "        fig_size = (15, 5)\n",
    "\n",
    "        # Gráfico 1: Visualizações dos top 9 vídeos\n",
    "        fig, ax = plt.subplots(figsize=(20, 5))\n",
    "        sns.barplot(x='title', y='viewCount', data=video_df.sort_values('viewCount', ascending=False)[0:9], ax=ax)\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "        ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}K'.format(x / 1000)))\n",
    "        ax.set_title(\"Top 9 Vídeos por Contagem de Visualizações\")\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Gráfico 2: Distribuição de visualizações por canal\n",
    "        fig, ax = plt.subplots(figsize=(20, 5))\n",
    "        sns.violinplot(x='channelTitle', y='viewCount', data=video_df, ax=ax, inner=\"quartile\")\n",
    "        ax.set_title(\"Distribuição de Visualizações por Canal\")\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Gráfico 3: WordCloud dos títulos\n",
    "        fig, ax = plt.subplots(figsize=(31, 10))\n",
    "        wordcloud = WordCloud(width=800, height=400, random_state=1, background_color='white', colormap='viridis').generate(all_words_str)\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\"WordCloud dos Títulos\")\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Gráfico 4: Publicações por dia da semana\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        day_df.reset_index().plot.bar(x='day', y='count', rot=0, ax=ax)\n",
    "        ax.set_title(\"Contagem de Publicações por Dia da Semana\")\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# print(\"Relatório PDF gerado com sucesso como 'youtube_report_final_design.pdf'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868711c6-84f3-4fff-840d-69eebc58777e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gerando o relatorio em PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7d5f5-217d-4c8b-abca-5ec6fe54ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_pdf_report(video_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dashboard_yt)",
   "language": "python",
   "name": "dashboard_yt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
